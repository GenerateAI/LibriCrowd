{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crowdsource LibriSpeech Relabeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, string\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'train_other_60h'\n",
    "folder = '/Users/gajian/Dropbox/Academia/Database/'\n",
    "process = 'process' # process, process2, process5\n",
    "data_dir = os.path.join(folder, 'LibriSpeech', 'batch_result', process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_nums = [60007, 60008, 60012]\n"
     ]
    }
   ],
   "source": [
    "batch_nums = sorted([int(file.split('.csv')[0]) for file in os.listdir(data_dir) if '.csv' in file and '_out' not in file])\n",
    "print('batch_nums =', batch_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio2utt(audio_url):\n",
    "    if '/' in audio_url:\n",
    "        audio_url = audio_url.split('/')[-1]\n",
    "    audio = audio_url.split('.')[0]\n",
    "    book = audio.split('-')[0]\n",
    "    chap = audio.split('-')[1]\n",
    "    uttr = audio.split('-')[2]\n",
    "    utt = book + '_' + chap + '_' + str(int(uttr))\n",
    "    return utt\n",
    "\n",
    "\n",
    "num2words = {1: 'One', 2: 'Two', 3: 'Three', 4: 'Four', 5: 'Five', \\\n",
    "             6: 'Six', 7: 'Seven', 8: 'Eight', 9: 'Nine', 10: 'Ten', \\\n",
    "            11: 'Eleven', 12: 'Twelve', 13: 'Thirteen', 14: 'Fourteen', \\\n",
    "            15: 'Fifteen', 16: 'Sixteen', 17: 'Seventeen', 18: 'Eighteen', \\\n",
    "            19: 'Nineteen', 20: 'Twenty', 30: 'Thirty', 40: 'Forty', \\\n",
    "            50: 'Fifty', 60: 'Sixty', 70: 'Seventy', 80: 'Eighty', \\\n",
    "            90: 'Ninety', 0: 'Zero'}\n",
    "\n",
    "strnum2word = dict()\n",
    "for k in num2words:\n",
    "    strnum2word[str(k)] = num2words[k]\n",
    "\n",
    "\n",
    "def normalize_word(word):\n",
    "    word = strnum2word.get(word, word)\n",
    "    if word in ('okay', 'ok'): return 'OK'\n",
    "    if word in ('mr', 'mr.'): return 'Mister'\n",
    "    if word in ('ms', 'ms.'): return 'Miss'\n",
    "    if word == 'mrs.': return 'Misses'\n",
    "    if word == 'ya': return 'you'\n",
    "    if word in ('cos','coz'): return 'because'\n",
    "    if word in ('ah','eh','hm','um','er','ahhh'): return ''\n",
    "    if word == \"there's\": return 'there is'\n",
    "    if word == \"i'm\": return 'i am'\n",
    "    if word == \"i'll\": return 'i will'\n",
    "    if word == \"it's\": return 'it is'\n",
    "    if word == \"she's\": return 'she is'\n",
    "    if word == \"he's\": return 'he is'\n",
    "    if word == \"where's\": return 'where is'\n",
    "    if word == \"what's\": return 'what is'\n",
    "    if word == \"when's\": return 'when is'\n",
    "    if word == \"why's\": return 'why is'\n",
    "    if word == \"who's\": return 'who is'\n",
    "    if word == \"you're\": return 'you are'\n",
    "    if word == \"you've\": return 'you have'\n",
    "    if word == \"don't\": return 'do not'\n",
    "    if word == \"didn't\": return 'did not'\n",
    "    if word == \"couldn't\": return 'could not'\n",
    "    if word == \"won't\": return 'will not'\n",
    "    if word == \"wasn't\": return 'was not'\n",
    "    if word == \"o'clock\": return 'oclock'\n",
    "    if word == \"dwarf's\": return 'dwarfs'\n",
    "    if word == 'wanna': return 'want to'\n",
    "    if word == 'k': return 'OK'\n",
    "    if word == 'anytime': return 'any time'\n",
    "    if word[-1] == '.' and word not in ('a.m.','p.m.'): return word[:-1]\n",
    "    return word.lower()\n",
    "\n",
    "\n",
    "def normalize_trans(trans):\n",
    "    trans = trans.lower()\n",
    "    trans = trans.replace('?','').replace(',','').replace('.','')\n",
    "    words = trans.split()\n",
    "    for i in range(len(words)):\n",
    "        words[i] = normalize_word(words[i])\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Gold and Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gold = pd.read_csv(os.path.join(folder, 'LibriSpeech', 'librispeech_{:s}_trans.csv'.format(dataset_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5188 entries, 0 to 5187\n",
      "Data columns (total 32 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   HITId                        5188 non-null   object \n",
      " 1   HITTypeId                    5188 non-null   object \n",
      " 2   Title                        5188 non-null   object \n",
      " 3   Description                  5188 non-null   object \n",
      " 4   Keywords                     5188 non-null   object \n",
      " 5   Reward                       5188 non-null   object \n",
      " 6   CreationTime                 5188 non-null   object \n",
      " 7   MaxAssignments               5188 non-null   int64  \n",
      " 8   RequesterAnnotation          5188 non-null   object \n",
      " 9   AssignmentDurationInSeconds  5188 non-null   int64  \n",
      " 10  AutoApprovalDelayInSeconds   5188 non-null   int64  \n",
      " 11  Expiration                   5188 non-null   object \n",
      " 12  NumberOfSimilarHITs          0 non-null      float64\n",
      " 13  LifetimeInSeconds            0 non-null      float64\n",
      " 14  AssignmentId                 5188 non-null   object \n",
      " 15  WorkerId                     5188 non-null   object \n",
      " 16  AssignmentStatus             5188 non-null   object \n",
      " 17  AcceptTime                   5188 non-null   object \n",
      " 18  SubmitTime                   5188 non-null   object \n",
      " 19  AutoApprovalTime             5188 non-null   object \n",
      " 20  ApprovalTime                 4511 non-null   object \n",
      " 21  RejectionTime                515 non-null    object \n",
      " 22  RequesterFeedback            515 non-null    object \n",
      " 23  WorkTimeInSeconds            5188 non-null   int64  \n",
      " 24  LifetimeApprovalRate         5188 non-null   object \n",
      " 25  Last30DaysApprovalRate       5188 non-null   object \n",
      " 26  Last7DaysApprovalRate        5188 non-null   object \n",
      " 27  Input.audio_url              5188 non-null   object \n",
      " 28  Answer.transcription         5187 non-null   object \n",
      " 29  Approve                      0 non-null      float64\n",
      " 30  Reject                       0 non-null      float64\n",
      " 31  batch_num                    5188 non-null   int64  \n",
      "dtypes: float64(4), int64(5), object(23)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_submits = []\n",
    "df_submit_aggs = []\n",
    "for batch_num in batch_nums:\n",
    "    df_submit = pd.read_csv(os.path.join(folder, 'LibriSpeech', 'batch_result/{:s}/{:d}.csv'.format(process, batch_num)))\n",
    "    ori_cols = df_submit.columns\n",
    "    df_submit_agg = df_submit\n",
    "    df_submit = df_submit[df_submit['Input.audio_url'].apply(lambda x: '.txt' not in x)]\n",
    "    df_submits.append(df_submit)\n",
    "    df_submit_agg['batch_num'] = batch_num\n",
    "    df_submit_aggs.append(df_submit_agg)\n",
    "df_submit_all = pd.concat(df_submit_aggs).reset_index(drop=True)\n",
    "df_submit_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit_all = df_submit_all[df_submit_all['AssignmentStatus'] == 'Submitted']\n",
    "df_submit_all['utt'] = df_submit_all['Input.audio_url'].apply(lambda x: audio2utt(x))\n",
    "df_check = df_submit_all.merge(df_gold[['utt','gold_trans']], on = ['utt'], how = 'left')\n",
    "df_check = df_check.rename(columns={'Answer.transcription':'std_trans'}).reset_index(drop=True)\n",
    "df_check['std_trans'] = df_check['std_trans'].fillna('ImputedNA')\n",
    "df_check['num_q_mark'] = df_check['std_trans'].apply(lambda x: x.count('?'))\n",
    "df_check['gold_trans'] = df_check['gold_trans'].apply(lambda x: normalize_trans(x))\n",
    "df_check['std_trans'] = df_check['std_trans'].apply(lambda x: normalize_trans(x))\n",
    "if len(df_check) == 0:\n",
    "    print('No pending task in batch_nums:', batch_nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_edit_distance(source: list, target: list, insert_cost=3, delete_cost=3, replace_cost=4):\n",
    "    \"\"\"\n",
    "    Given two lists of tokens, calculate weighted edit distance\n",
    "    https://code.amazon.com/packages/DeepADSPhase1/blobs/6930484f38136e49395dcb3e7df8baaec97e40c9/--/src/deep_ads_phase1/sentence_utils_wlm.py#L230\n",
    "    \"\"\"\n",
    "    m = len(source)\n",
    "    n = len(target)\n",
    "    if target == source:\n",
    "        return 0\n",
    "    if m == 0:\n",
    "        return n\n",
    "    if n == 0:\n",
    "        return m\n",
    "    d = np.zeros((n + 1, m + 1))\n",
    "    f = np.zeros((n + 1, m + 1))\n",
    "    d[0, 0] = 0\n",
    "    f[0, 0] = 0\n",
    "    for i in range(1, n + 1):\n",
    "        d[i, 0] = d[i - 1, 0] + insert_cost\n",
    "        f[i, 0] = f[i - 1, 0] + 1\n",
    "    for j in range(1, m + 1):\n",
    "        d[0, j] = d[0, j - 1] + delete_cost\n",
    "        f[0, j] = f[0, j - 1] + 1\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            multiplier = int(not target[i - 1] == source[j - 1])\n",
    "            d_costs = [d[i - 1, j] + insert_cost,\n",
    "                       d[i - 1, j - 1] + multiplier * replace_cost,\n",
    "                       d[i, j - 1] + delete_cost]\n",
    "            f_costs = [f[i - 1, j] + 1,\n",
    "                       f[i - 1, j - 1] + multiplier,\n",
    "                       f[i, j - 1] + 1]\n",
    "            idx = int(np.argmin(d_costs))\n",
    "            assert isinstance(idx, int)\n",
    "            d[i, j] = d_costs[idx]\n",
    "            f[i, j] = f_costs[idx]\n",
    "    return f[n, m]\n",
    "\n",
    "def compute_wer(t1, t2):\n",
    "    \"\"\"\n",
    "    Given two transcriptions, calculate Word Error Rate (WER)\n",
    "    https://code.amazon.com/packages/DeepADSPhase1/blobs/6930484f38136e49395dcb3e7df8baaec97e40c9/--/src/deep_ads_phase1/sentence_utils_wlm.py#L174\n",
    "    \"\"\"\n",
    "    word_error_count = cost_edit_distance(t1.split(), t2.split())\n",
    "    return word_error_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check['gold_trans_stc'] = df_check['gold_trans'].apply(lambda x: len(x.split()))\n",
    "df_check['std_trans_stc'] = df_check['std_trans'].apply(lambda x: len(x.split()))\n",
    "df_check['std_trans_wec'] = df_check.apply(lambda x: compute_wer(x.gold_trans, x.std_trans), axis=1)\n",
    "# df_check.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wer_mean = 0.1658, wer_oracle = 0.1658, wer_max = 0.1658\n"
     ]
    }
   ],
   "source": [
    "df6 = df_check.groupby('utt').agg({'std_trans_wec': ['mean', 'min', 'max']})\n",
    "df7 = df_check.groupby('utt').agg({'gold_trans_stc': ['min']})\n",
    "wer_mean = df6[('std_trans_wec', 'mean')].sum() / df7[('gold_trans_stc', 'min')].sum()\n",
    "wer_max = df6[('std_trans_wec', 'max')].sum() / df7[('gold_trans_stc', 'min')].sum()\n",
    "wer_oracle = df6[('std_trans_wec', 'min')].sum() / df7[('gold_trans_stc', 'min')].sum()\n",
    "print('wer_mean = {:.4f}, wer_oracle = {:.4f}, wer_max = {:.4f}'.format(wer_mean, wer_oracle, wer_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_trans_stc</th>\n",
       "      <th>std_trans_wec</th>\n",
       "      <th>wer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60007</th>\n",
       "      <td>328.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.310976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60008</th>\n",
       "      <td>670.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>0.302985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60012</th>\n",
       "      <td>3985.0</td>\n",
       "      <td>521.0</td>\n",
       "      <td>0.130740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>4983.0</td>\n",
       "      <td>826.0</td>\n",
       "      <td>0.165764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           gold_trans_stc  std_trans_wec       wer\n",
       "batch_num                                         \n",
       "60007               328.0          102.0  0.310976\n",
       "60008               670.0          203.0  0.302985\n",
       "60012              3985.0          521.0  0.130740\n",
       "All                4983.0          826.0  0.165764"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report = df_check[['gold_trans_stc','std_trans_wec','batch_num']].groupby(by=['batch_num']).sum()\n",
    "df_report['wer'] = df_report['std_trans_wec'] / df_report['gold_trans_stc']\n",
    "df_report.loc['All'] = [df_report['gold_trans_stc'].sum(), df_report['std_trans_wec'].sum(), df_report['std_trans_wec'].sum() / df_report['gold_trans_stc'].sum()] \n",
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict WER and Make Decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check['wer'] = df_check['std_trans_wec'] / df_check['gold_trans_stc']\n",
    "df_check['wec'] = df_check['std_trans_wec'] - df_check['num_q_mark']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wer threshold = 0.32, need relabeling: count = 31, percent = 0.19\n"
     ]
    }
   ],
   "source": [
    "relabeling = 0.2\n",
    "threshold = max(0.2, np.quantile(df_check['wer'], 1-relabeling))\n",
    "need_relabeling = (df_check['wer'] > threshold) & ((df_check['wec'] > 2) | (df_check['num_q_mark'] > df_check['gold_trans_stc'] * 0.5))\n",
    "print('wer threshold = {:.2f}, need relabeling: count = {:d}, percent = {:.2f}'.format(threshold, sum(need_relabeling), sum(need_relabeling)/len(df_check)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject_reason(df, batch_num):\n",
    "    gold_trans, std_trans = df.gold_trans, df.std_trans\n",
    "    gold_trans = gold_trans.replace(\"'\", '')\n",
    "    missing = (df.std_trans_stc < df.gold_trans_stc * 0.7)\n",
    "    wec = df.std_trans_wec\n",
    "    if missing:\n",
    "        reason = 'the transcription is not correct, missing a lot (batch id: {:d}). your answer: {:s}, groundtruth: {:s}. #errors = {:.0f}'\\\n",
    "        .format(batch_num, std_trans, gold_trans, wec)\n",
    "    else:\n",
    "        reason = 'the transcription is not correct, many errors (batch id: {:d}). your answer: {:s}, groundtruth: {:s}. #errors = {:.0f}'\\\n",
    "        .format(batch_num, std_trans, gold_trans, wec)\n",
    "    return reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b3/d7n5t47x4nl6wt3lhs2_stn1cdmymq/T/ipykernel_47596/2767985505.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_check['Reject'][need_relabeling] = df_check.apply(lambda x: reject_reason(x, x['batch_num']), axis=1)\n",
      "/var/folders/b3/d7n5t47x4nl6wt3lhs2_stn1cdmymq/T/ipykernel_47596/2767985505.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_check['Approve'][df_check['Reject'].isnull()] = 'x'\n"
     ]
    }
   ],
   "source": [
    "df_check['Reject'][need_relabeling] = df_check.apply(lambda x: reject_reason(x, x['batch_num']), axis=1)\n",
    "df_check['Approve'][df_check['Reject'].isnull()] = 'x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input.audio_url = 5735/48575/5735-48575-0001.flac\n",
      "Approve = nan\n",
      "Reject = the transcription is not correct, missing a lot (batch id: 60007). your answer: there is no help horsemen, groundtruth: there is no help for it but thou send out horsemen. #errors = 6\n",
      "std_trans = there is no help horsemen\n",
      "gold_trans = there is no help for it but thou send out horsemen\n",
      "std_trans_wec = 6.0\n",
      "wer = 0.5454545454545454\n"
     ]
    }
   ],
   "source": [
    "# double check\n",
    "if process == 'process':\n",
    "    cols = ['Input.audio_url','Approve','Reject','std_trans','gold_trans','std_trans_wec','wer']\n",
    "    df8 = df_check[need_relabeling].reset_index(drop=True)\n",
    "    i = 0\n",
    "    for col in cols:\n",
    "        if i < len(df8):\n",
    "            print('{:s} = {:s}'.format(col, str(df8[col][i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_num = 60007, n_reject = 08, rep_rate = 0.53\n",
      "batch_num = 60008, n_reject = 10, rep_rate = 0.43\n",
      "batch_num = 60012, n_reject = 13, rep_rate = 0.10\n",
      "batch_num = all, n_reject = 31, rep_rate = 0.19\n"
     ]
    }
   ],
   "source": [
    "cols = ['HITId','WorkerId','Approve','Reject']\n",
    "all_reject_cnt = 0\n",
    "for i, batch_num in enumerate(batch_nums):\n",
    "    df_submit = df_submits[i]\n",
    "    df_out = df_submit[ori_cols].drop(columns=['Approve','Reject']).merge(df_check[cols], on = ['HITId','WorkerId'])\n",
    "    df_out.to_csv(os.path.join(folder, 'LibriSpeech', 'batch_result/{:s}/{:d}_out.csv'.format(process, batch_num)), index=False)\n",
    "#     df_out.info()\n",
    "    n_reject = sum(~df_out['Reject'].isnull())\n",
    "    rep_rate  = n_reject / len(df_out)\n",
    "    all_reject_cnt += n_reject\n",
    "    print('batch_num = {:04d}, n_reject = {:02d}, rep_rate = {:.2f}'.format(batch_num, n_reject, rep_rate))\n",
    "print('batch_num = all, n_reject = {:02d}, rep_rate = {:.2f}'.format(all_reject_cnt, all_reject_cnt/len(df_check)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gold may have error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev-other: \n",
    "# 1585-131718-0017.flac\n",
    "# 1585-157660-0009.flac\n",
    "# 1650-167613-0006.flac hard and need domain knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr02",
   "language": "python",
   "name": "asr02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
