{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LibriCrowd Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, os, re, string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jiwer\n",
    "# wer is same as https://code.amazon.com/packages/DeepADSPhase1/blobs/6930484f38136e49395dcb3e7df8baaec97e40c9/--/src/deep_ads_phase1/sentence_utils_wlm.py#L230, replace_cost=3\n",
    "from utils.agreement import normalize\n",
    "from utils.rover import ROVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = './data/LibriSpeechCrowd'\n",
    "dataset = 'train-mixed-10h' # test-other, dev-other, test-clean, dev-clean, train-mixed-10h, train-other-10h\n",
    "goldpath = os.path.join(folder, 'librispeech_{:s}_trans.csv'.format(dataset.replace('-','_')))\n",
    "crowdpath = os.path.join(folder, 'librispeech_{:s}_crowd.csv'.format(dataset.replace('-','_')))\n",
    "crowdpath_5 = os.path.join(folder, 'librispeech_{:s}_crowd_5.csv'.format(dataset.replace('-','_')))\n",
    "crowdpath_raw = os.path.join(folder, 'librispeech_{:s}_crowd_raw.csv'.format(dataset.replace('-','_')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Gold and Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_csv_filenames(path_to_dir, suffix='.csv'):\n",
    "    filenames = os.listdir(path_to_dir)\n",
    "    filepaths = [os.path.join(path_to_dir, filename) for filename in filenames if filename.endswith(suffix)]\n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio2utt(audio_url):\n",
    "    audio = audio_url.split('.')[0]\n",
    "    book = audio.split('-')[0]\n",
    "    chap = audio.split('-')[1]\n",
    "    try:\n",
    "        uttr = audio.split('-')[2]\n",
    "    except:\n",
    "        print(audio_url)\n",
    "    utt = book + '_' + chap + '_' + str(int(uttr))\n",
    "    return utt\n",
    "\n",
    "\n",
    "num2words = {1: 'One', 2: 'Two', 3: 'Three', 4: 'Four', 5: 'Five', \\\n",
    "             6: 'Six', 7: 'Seven', 8: 'Eight', 9: 'Nine', 10: 'Ten', \\\n",
    "            11: 'Eleven', 12: 'Twelve', 13: 'Thirteen', 14: 'Fourteen', \\\n",
    "            15: 'Fifteen', 16: 'Sixteen', 17: 'Seventeen', 18: 'Eighteen', \\\n",
    "            19: 'Nineteen', 20: 'Twenty', 30: 'Thirty', 40: 'Forty', \\\n",
    "            50: 'Fifty', 60: 'Sixty', 70: 'Seventy', 80: 'Eighty', \\\n",
    "            90: 'Ninety', 0: 'Zero'}\n",
    "\n",
    "strnum2word = dict()\n",
    "for k in num2words:\n",
    "    strnum2word[str(k)] = num2words[k]\n",
    "\n",
    "\n",
    "def normalize_word(word):\n",
    "    word = strnum2word.get(word, word)\n",
    "    if word in ('okay', 'ok'): return 'OK'\n",
    "    if word in ('mr', 'mr.'): return 'Mister'\n",
    "    if word in ('ms', 'ms.'): return 'Miss'\n",
    "    if word == 'mrs.': return 'Misses'\n",
    "    if word == 'ya': return 'you'\n",
    "    if word in ('cos','coz'): return 'because'\n",
    "    if word in ('ah','eh','hm','um','er','ahhh'): return ''\n",
    "    if word == \"there's\": return 'there is'\n",
    "    if word == \"i'm\": return 'i am'\n",
    "    if word == \"where's\": return 'where is'\n",
    "    if word == \"what's\": return 'what is'\n",
    "    if word == \"when's\": return 'when is'\n",
    "    if word == \"why's\": return 'why is'\n",
    "    if word == \"who's\": return 'who is'\n",
    "    if word == \"you're\": return 'you are'\n",
    "    if word == 'wanna': return 'want to'\n",
    "    if word == 'k': return 'OK'\n",
    "    if word == 'anytime': return 'any time'\n",
    "    if word[-1] == '.' and word not in ('a.m.','p.m.'): return word[:-1]\n",
    "    return word.lower()\n",
    "\n",
    "\n",
    "def normalize_trans(trans):\n",
    "    trans = trans.lower()\n",
    "    trans = trans.replace('?','').replace(',','').replace('.','')\n",
    "    words = trans.split()\n",
    "    for i in range(len(words)):\n",
    "        words[i] = normalize_word(words[i])\n",
    "    trans = ' '.join(words)\n",
    "#     res = jiwer.ExpandCommonEnglishContractions()(trans)\n",
    "    return trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SubmitTime2DateTime(s):\n",
    "    '''\n",
    "    s = 'Wed Dec 28 17:35:02 PST 2022'\n",
    "    t = '2022-12-28 17:35:02'\n",
    "    '''\n",
    "    e = '%a %b %d %H:%M:%S %Z %Y'\n",
    "    d = datetime.datetime.strptime(s, e)\n",
    "    t = datetime.datetime.strftime(d, '%Y-%m-%d %H:%M:%S')\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2763 entries, 0 to 2762\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   utt         2763 non-null   object\n",
      " 1   gold_trans  2763 non-null   object\n",
      " 2   std_trans   2763 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 64.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_gold = pd.read_csv(goldpath)\n",
    "df_gold.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = find_csv_filenames(os.path.join(folder, dataset))\n",
    "df_submits = []\n",
    "for filepath in filepaths:\n",
    "    df_submits.append(pd.read_csv(filepath))\n",
    "df_submit = pd.concat(df_submits)\n",
    "df_submit.dropna(subset=['Input.audio_url'], inplace=True)\n",
    "df_submit = df_submit[df_submit['Input.audio_url'].apply(lambda x:'.txt' not in x)].reset_index(drop=True)\n",
    "df_submit['taskId'] = df_submit['HITId'] + '|' + df_submit['WorkerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14231 entries, 0 to 14230\n",
      "Data columns (total 36 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   HITId                        14231 non-null  object \n",
      " 1   HITTypeId                    14231 non-null  object \n",
      " 2   Title                        14231 non-null  object \n",
      " 3   Description                  14231 non-null  object \n",
      " 4   Keywords                     14231 non-null  object \n",
      " 5   Reward                       14231 non-null  object \n",
      " 6   CreationTime                 14231 non-null  object \n",
      " 7   MaxAssignments               14231 non-null  int64  \n",
      " 8   RequesterAnnotation          14231 non-null  object \n",
      " 9   AssignmentDurationInSeconds  14231 non-null  int64  \n",
      " 10  AutoApprovalDelayInSeconds   14231 non-null  int64  \n",
      " 11  Expiration                   14231 non-null  object \n",
      " 12  NumberOfSimilarHITs          0 non-null      float64\n",
      " 13  LifetimeInSeconds            0 non-null      float64\n",
      " 14  AssignmentId                 14231 non-null  object \n",
      " 15  WorkerId                     14231 non-null  object \n",
      " 16  AssignmentStatus             14231 non-null  object \n",
      " 17  AcceptTime                   14231 non-null  object \n",
      " 18  SubmitTime                   14231 non-null  object \n",
      " 19  AutoApprovalTime             14231 non-null  object \n",
      " 20  ApprovalTime                 13803 non-null  object \n",
      " 21  RejectionTime                428 non-null    object \n",
      " 22  RequesterFeedback            428 non-null    object \n",
      " 23  WorkTimeInSeconds            14231 non-null  int64  \n",
      " 24  LifetimeApprovalRate         14231 non-null  object \n",
      " 25  Last30DaysApprovalRate       14231 non-null  object \n",
      " 26  Last7DaysApprovalRate        14231 non-null  object \n",
      " 27  Input.audio_url              14231 non-null  object \n",
      " 28  std_trans                    14231 non-null  object \n",
      " 29  Approve                      0 non-null      float64\n",
      " 30  Reject                       0 non-null      float64\n",
      " 31  taskId                       14231 non-null  object \n",
      " 32  utt                          14231 non-null  object \n",
      " 33  gold_trans                   14231 non-null  object \n",
      " 34  num_q_mark                   14231 non-null  int64  \n",
      " 35  submittime                   14231 non-null  object \n",
      "dtypes: float64(4), int64(5), object(27)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# merge std with gold and rename columns\n",
    "df_submit['utt'] = df_submit['Input.audio_url'].apply(lambda x: audio2utt(x))\n",
    "df_all = df_submit.merge(df_gold[['utt','gold_trans']], on = ['utt'], how = 'left')\n",
    "df_all = df_all.rename(columns={'Answer.transcription':'std_trans'})\n",
    "df_all['std_trans'] = df_all['std_trans'].fillna('ImputedNA')\n",
    "df_all['num_q_mark'] = df_all['std_trans'].apply(lambda x: x.count('?'))\n",
    "df_all['submittime'] = df_all['SubmitTime'].apply(lambda x: SubmitTime2DateTime(x))\n",
    "# normalize trans\n",
    "df_all['gold_trans'] = df_all['gold_trans'].apply(lambda x: normalize_trans(x))\n",
    "df_all['std_trans'] = df_all['std_trans'].apply(lambda x: normalize_trans(x))\n",
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_edit_distance(source: list, target: list, insert_cost=1, delete_cost=1, replace_cost=1):\n",
    "    \"\"\"\n",
    "    Given two lists of tokens, calculate weighted edit distance\n",
    "    https://code.amazon.com/packages/DeepADSPhase1/blobs/6930484f38136e49395dcb3e7df8baaec97e40c9/--/src/deep_ads_phase1/sentence_utils_wlm.py#L230\n",
    "    \"\"\"\n",
    "    m = len(source)\n",
    "    n = len(target)\n",
    "    if target == source:\n",
    "        return 0\n",
    "    if m == 0:\n",
    "        return n\n",
    "    if n == 0:\n",
    "        return m\n",
    "    d = np.zeros((n + 1, m + 1))\n",
    "    f = np.zeros((n + 1, m + 1))\n",
    "    d[0, 0] = 0\n",
    "    f[0, 0] = 0\n",
    "    for i in range(1, n + 1):\n",
    "        d[i, 0] = d[i - 1, 0] + insert_cost\n",
    "        f[i, 0] = f[i - 1, 0] + 1\n",
    "    for j in range(1, m + 1):\n",
    "        d[0, j] = d[0, j - 1] + delete_cost\n",
    "        f[0, j] = f[0, j - 1] + 1\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            multiplier = int(not target[i - 1] == source[j - 1])\n",
    "            d_costs = [d[i - 1, j] + insert_cost,\n",
    "                       d[i - 1, j - 1] + multiplier * replace_cost,\n",
    "                       d[i, j - 1] + delete_cost]\n",
    "            f_costs = [f[i - 1, j] + 1,\n",
    "                       f[i - 1, j - 1] + multiplier,\n",
    "                       f[i, j - 1] + 1]\n",
    "            idx = int(np.argmin(d_costs))\n",
    "            assert isinstance(idx, int)\n",
    "            d[i, j] = d_costs[idx]\n",
    "            f[i, j] = f_costs[idx]\n",
    "    return f[n, m]\n",
    "\n",
    "def compute_wer(t1, t2):\n",
    "    \"\"\"\n",
    "    Given two transcriptions, calculate Word Error Rate (WER)\n",
    "    https://code.amazon.com/packages/DeepADSPhase1/blobs/6930484f38136e49395dcb3e7df8baaec97e40c9/--/src/deep_ads_phase1/sentence_utils_wlm.py#L174\n",
    "    \"\"\"\n",
    "    word_error_count = cost_edit_distance(t1.split(), t2.split())\n",
    "    return word_error_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wer(df, std_trans='std_trans', reuse=True):\n",
    "    if reuse == False or 'std_trans_wec' not in df.columns:\n",
    "        print('compute std_trans_wec ...', end='\\r')\n",
    "        df['gold_trans_stc'] = df['gold_trans'].apply(lambda x: len(x.split()))\n",
    "        df['std_trans_stc']  = df[std_trans].apply(lambda x: len(x.split()))\n",
    "        df['std_trans_wec']  = df.apply(lambda x: compute_wer(x.gold_trans, x[std_trans]), axis=1)\n",
    "    df1 = df.groupby('utt').agg({'std_trans_wec': ['mean', 'min', 'max']})\n",
    "    df2 = df.groupby('utt').agg({'gold_trans_stc': ['min']})\n",
    "    wer_avg = df1[('std_trans_wec', 'mean')].sum() / df2[('gold_trans_stc', 'min')].sum()\n",
    "    wer_min = df1[('std_trans_wec', 'min')].sum()  / df2[('gold_trans_stc', 'min')].sum()\n",
    "    wer_max = df1[('std_trans_wec', 'max')].sum()  / df2[('gold_trans_stc', 'min')].sum()\n",
    "    return wer_avg, wer_min, wer_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(gold_trans, std_trans):\n",
    "    metrics = jiwer.compute_measures(gold_trans, std_trans)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['gold_trans_stc'] = df_all['gold_trans'].apply(lambda x: len(x.split()))\n",
    "df_all['std_trans_stc']  = df_all['std_trans'].apply(lambda x: len(x.split()))\n",
    "df_all['std_trans_wec']  = df_all.apply(lambda x: compute_wer(x.gold_trans, x.std_trans), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approved: count = 13803, wer_avg = 0.0489, wer_min = 0.0205, wer_max = 0.1053\n",
      "Rejected: count =   428, wer_avg = 0.6368, wer_min = 0.6088, wer_max = 0.6676\n"
     ]
    }
   ],
   "source": [
    "df_approved = df_all[df_all['AssignmentStatus'] == 'Approved'].reset_index(drop=True)\n",
    "df_rejected = df_all[df_all['AssignmentStatus'] == 'Rejected'].reset_index(drop=True)\n",
    "wer_avg_approve, wer_min_approve, wer_max_approve = get_wer(df_approved)\n",
    "wer_avg_reject,  wer_min_reject,  wer_max_reject  = get_wer(df_rejected)\n",
    "print('Approved: count = {:5d}, wer_avg = {:.4f}, wer_min = {:.4f}, wer_max = {:.4f}'.format(len(df_approved), wer_avg_approve, wer_min_approve, wer_max_approve))\n",
    "print('Rejected: count = {:5d}, wer_avg = {:.4f}, wer_min = {:.4f}, wer_max = {:.4f}'.format(len(df_rejected), wer_avg_reject, wer_min_reject, wer_max_reject))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Type Statistics for Approved and Rejected Transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_type(df, std_trans='std_trans'):\n",
    "    df[std_trans] = df[std_trans].fillna('')\n",
    "    df['std_trans_metrics'] = df.apply(lambda x: compute_metrics(x.gold_trans, x[std_trans]), axis=1)\n",
    "    df['gold_trans_stc'] = df['gold_trans'].apply(lambda x: len(x.split()))\n",
    "    df['std_trans_stc'] = df[std_trans].apply(lambda x: len(x.split()))\n",
    "    df['std_trans_del'] = df['std_trans_metrics'].apply(lambda x: x['deletions'])\n",
    "    df['std_trans_ins'] = df['std_trans_metrics'].apply(lambda x: x['insertions'])\n",
    "    df['std_trans_sub'] = df['std_trans_metrics'].apply(lambda x: x['substitutions'])\n",
    "    df['std_trans_wec'] = df['std_trans_metrics'].apply(lambda x: x['deletions'] + x['insertions'] + x['substitutions'])\n",
    "    res = dict()\n",
    "    res['CNT'] = len(df)\n",
    "    res['LEN'] = df['std_trans_stc'].sum() / len(df)\n",
    "    res['DEL'] = df['std_trans_del'].sum() / df['gold_trans_stc'].sum() * 100\n",
    "    res['INS'] = df['std_trans_ins'].sum() / df['gold_trans_stc'].sum() * 100\n",
    "    res['SUB'] = df['std_trans_sub'].sum() / df['gold_trans_stc'].sum() * 100\n",
    "    res['WER'] = df['std_trans_wec'].sum() / df['gold_trans_stc'].sum() * 100\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset = train-mixed-10h, approved: count = 13803, len = 35.2, del = 0.87%, ins = 0.44%, sub = 3.58%, wer = 4.89%\n",
      "dataset = train-mixed-10h, rejected: count = 428, len = 17.1, del = 44.72%, ins = 1.74%, sub = 15.40%, wer = 61.85%\n"
     ]
    }
   ],
   "source": [
    "res = error_type(df_approved)\n",
    "print('dataset = {:s}, approved: count = {:d}, len = {:.1f}, del = {:.2f}%, ins = {:.2f}%, sub = {:.2f}%, wer = {:.2f}%'\\\n",
    "      .format(dataset, res['CNT'], res['LEN'], res['DEL'], res['INS'], res['SUB'], res['WER']))\n",
    "res = error_type(df_rejected)\n",
    "print('dataset = {:s}, rejected: count = {:d}, len = {:.1f}, del = {:.2f}%, ins = {:.2f}%, sub = {:.2f}%, wer = {:.2f}%'\\\n",
    "      .format(dataset, res['CNT'], res['LEN'], res['DEL'], res['INS'], res['SUB'], res['WER']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['HITId','HITTypeId','Title','Description','Keywords','Reward','CreationTime','MaxAssignments','RequesterAnnotation','AssignmentDurationInSeconds','AutoApprovalDelayInSeconds','Expiration','AssignmentId','WorkerId','AssignmentStatus','AcceptTime','SubmitTime','AutoApprovalTime','ApprovalTime','RejectionTime','RequesterFeedback','WorkTimeInSeconds','LifetimeApprovalRate','Last30DaysApprovalRate','Last7DaysApprovalRate','Input.audio_url','std_trans','utt','gold_trans','num_q_mark','submittime','gold_trans_stc','std_trans_stc','std_trans_wec','taskId']\n",
    "df_crowd_raw = df_all[cols].reset_index(drop=True)\n",
    "df_crowd_raw.to_csv(crowdpath_raw, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relabeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['utt','submittime','AssignmentId']\n",
    "df = df_all[cols].sort_values(by=['submittime','utt']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.groupby('utt', as_index=False).apply(lambda x: x if len(x)==1 else x.iloc[[0]]).reset_index(level=0, drop=True)\n",
    "df2 = df.groupby('utt', as_index=False).apply(lambda x: x if len(x)==1 else x.iloc[[1]]).reset_index(level=0, drop=True)\n",
    "df3 = df.groupby('utt', as_index=False).apply(lambda x: x if len(x)==1 else x.iloc[[2]]).reset_index(level=0, drop=True)\n",
    "df4 = df.groupby('utt', as_index=False).apply(lambda x: x if len(x)==1 else x.iloc[[3]]).reset_index(level=0, drop=True)\n",
    "df5 = df.groupby('utt', as_index=False).apply(lambda x: x if len(x)==1 else x.iloc[[4]]).reset_index(level=0, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5 = pd.concat([df1, df2, df3, df4, df5])\n",
    "df_before_relabel = df_all.merge(df_5[['AssignmentId']], on = ['AssignmentId'], how='right')\n",
    "df_after_relabel  = df_approved.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Relabeling: wer_avg = 0.0597, wer_min = 0.0209, wer_max = 0.1541\n",
      "After  Relabeling: wer_avg = 0.0489, wer_min = 0.0205, wer_max = 0.1053\n",
      "Relabeling percent = 3.10%, WER improve = 108 bps\n",
      "Number of workers: before = 581, after = 616\n"
     ]
    }
   ],
   "source": [
    "wer_avg_before, wer_min_before, wer_max_before = get_wer(df_before_relabel)\n",
    "wer_avg_after, wer_min_after, wer_max_after = get_wer(df_after_relabel)\n",
    "print('Before Relabeling: wer_avg = {:.4f}, wer_min = {:.4f}, wer_max = {:.4f}'.format(wer_avg_before, wer_min_before, wer_max_before))\n",
    "print('After  Relabeling: wer_avg = {:.4f}, wer_min = {:.4f}, wer_max = {:.4f}'.format(wer_avg_after, wer_min_after, wer_max_after))\n",
    "relabel_rate = len(df_rejected) / len(df_approved)\n",
    "num_worker_before = len(set(df_before_relabel['WorkerId']))\n",
    "num_worker_after  = len(set(df_all['WorkerId']))\n",
    "print('Relabeling percent = {:.2f}%, WER improve = {:.0f} bps'.format(100*relabel_rate, 1e4*(wer_avg_before - wer_avg_after)))\n",
    "print('Number of workers: before = {:d}, after = {:d}'.format(num_worker_before, num_worker_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random and Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn1 = lambda x: x.loc[np.random.choice(x.index, size=1, replace=False) if len(x) >= 4 else np.random.choice(x.index, 4, True),:]\n",
    "fn2 = lambda x: x.loc[np.random.choice(x.index, size=2, replace=False) if len(x) >= 4 else np.random.choice(x.index, 4, True),:]\n",
    "fn3 = lambda x: x.loc[np.random.choice(x.index, size=3, replace=False) if len(x) >= 4 else np.random.choice(x.index, 4, True),:]\n",
    "fn4 = lambda x: x.loc[np.random.choice(x.index, size=4, replace=False) if len(x) >= 4 else np.random.choice(x.index, 4, True),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_before_random_1 = df_before_relabel.groupby('utt', as_index=False).apply(fn1).reset_index(drop=True)\n",
    "df_before_random_2 = df_before_relabel.groupby('utt', as_index=False).apply(fn2).reset_index(drop=True)\n",
    "df_before_random_3 = df_before_relabel.groupby('utt', as_index=False).apply(fn3).reset_index(drop=True)\n",
    "df_before_random_4 = df_before_relabel.groupby('utt', as_index=False).apply(fn4).reset_index(drop=True)\n",
    "df_after_random_1  = df_after_relabel.groupby('utt', as_index=False).apply(fn1).reset_index(drop=True)\n",
    "df_after_random_2  = df_after_relabel.groupby('utt', as_index=False).apply(fn2).reset_index(drop=True)\n",
    "df_after_random_3  = df_after_relabel.groupby('utt', as_index=False).apply(fn3).reset_index(drop=True)\n",
    "df_after_random_4  = df_after_relabel.groupby('utt', as_index=False).apply(fn4).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_random_before, _, _  = get_wer(df_before_random_1)\n",
    "wer_random_after, _, _   = get_wer(df_after_random_1)\n",
    "_, wer_oracle2_before, _ = get_wer(df_before_random_2)\n",
    "_, wer_oracle2_after, _  = get_wer(df_after_random_2)\n",
    "_, wer_oracle3_before, _ = get_wer(df_before_random_3)\n",
    "_, wer_oracle3_after, _  = get_wer(df_after_random_3)\n",
    "_, wer_oracle4_before, _ = get_wer(df_before_random_4)\n",
    "_, wer_oracle4_after, _  = get_wer(df_after_random_4)\n",
    "wer_oracle5_before       = wer_min_before\n",
    "wer_oracle5_after        = wer_min_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wer_random1_before = 0.0591, wer_random1_after = 0.0487\n",
      "wer_oracle2_before = 0.0307, wer_oracle2_after = 0.0286\n",
      "wer_oracle3_before = 0.0246, wer_oracle3_after = 0.0247\n",
      "wer_oracle4_before = 0.0224, wer_oracle4_after = 0.0220\n",
      "wer_oracle5_before = 0.0209, wer_oracle5_after = 0.0205\n"
     ]
    }
   ],
   "source": [
    "print('wer_random1_before = {:.4f}, wer_random1_after = {:.4f}'.format(wer_random_before, wer_random_after))\n",
    "print('wer_oracle2_before = {:.4f}, wer_oracle2_after = {:.4f}'.format(wer_oracle2_before, wer_oracle2_after))\n",
    "print('wer_oracle3_before = {:.4f}, wer_oracle3_after = {:.4f}'.format(wer_oracle3_before, wer_oracle3_after))\n",
    "print('wer_oracle4_before = {:.4f}, wer_oracle4_after = {:.4f}'.format(wer_oracle4_before, wer_oracle4_after))\n",
    "print('wer_oracle5_before = {:.4f}, wer_oracle5_after = {:.4f}'.format(wer_oracle5_before, wer_oracle5_after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longest std_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_longest(x):\n",
    "    ref = -1\n",
    "    res = -1\n",
    "    for idx, std_trans_stc in zip(x.index, x.std_trans_stc):\n",
    "        if std_trans_stc > ref:\n",
    "            ref = std_trans_stc\n",
    "            res = idx\n",
    "    return x.loc[res,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_longest_before = df_before_relabel.groupby('utt', as_index=False).apply(f_longest).reset_index(drop=True)\n",
    "df_longest_after  = df_after_relabel.groupby('utt', as_index=False).apply(f_longest).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Highest approve_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_before_relabel['approve_rate'] = df_before_relabel['LifetimeApprovalRate'].apply(lambda x: int(x.split('%')[0])/100)\n",
    "df_after_relabel['approve_rate']  = df_after_relabel['LifetimeApprovalRate'].apply(lambda x: int(x.split('%')[0])/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_highest(x):\n",
    "    ref = -1\n",
    "    res = -1\n",
    "    for idx, approve_rate in zip(x.index, x.approve_rate):\n",
    "        if approve_rate > ref:\n",
    "            ref = approve_rate\n",
    "            res = idx\n",
    "    return x.loc[res,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_highest_before = df_before_relabel.groupby('utt', as_index=False).apply(f_highest).reset_index(drop=True)\n",
    "df_highest_after  = df_after_relabel.groupby('utt', as_index=False).apply(f_highest).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oracle Worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_best(x):\n",
    "    ref = 9999\n",
    "    res = -1\n",
    "    for idx, wec in zip(x.index, x.std_trans_wec):\n",
    "        if wec < ref:\n",
    "            ref = wec\n",
    "            res = idx\n",
    "    return x.loc[res,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_worst(x):\n",
    "    ref = -1\n",
    "    res = -1\n",
    "    for idx, wec in zip(x.index, x.std_trans_wec):\n",
    "        if wec > ref:\n",
    "            ref = wec\n",
    "            res = idx\n",
    "    return x.loc[res,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_before = df_before_relabel.groupby('utt', as_index=False).apply(f_best).reset_index(drop=True)\n",
    "df_best_after  = df_after_relabel.groupby('utt', as_index=False).apply(f_best).reset_index(drop=True)\n",
    "df_worst_before = df_before_relabel.groupby('utt', as_index=False).apply(f_worst).reset_index(drop=True)\n",
    "df_worst_after  = df_after_relabel.groupby('utt', as_index=False).apply(f_worst).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "915ace297c9a4e6a978cdf4003643e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2763 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rover_before = ROVER().fit_predict(df_before_relabel[['utt','std_trans']].rename(columns={\"utt\": \"task\", \"std_trans\": \"output\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "589a39cc405e464fafbe6b73cc46d398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2762 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rover_after = ROVER().fit_predict(df_after_relabel[['utt','std_trans']].rename(columns={\"utt\": \"task\", \"std_trans\": \"output\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_before = df_before_relabel.merge(rover_before.reset_index(), left_on='utt', right_on='task').groupby('utt').agg(lambda x: x.iloc[0]).reset_index()\n",
    "df_eval_before.rename(columns={'output': 'std_trans_rover'}, inplace=True)\n",
    "df_eval_after = df_after_relabel.merge(rover_after.reset_index(), left_on='utt', right_on='task').groupby('utt').agg(lambda x: x.iloc[0]).reset_index()\n",
    "df_eval_after.rename(columns={'output': 'std_trans_rover'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wer_correct_before, _, _  = get_wer(df_eval_before, std_trans='std_trans_rover', reuse=False)\n",
    "# wer_correct_after, _, _   = get_wer(df_eval_after, std_trans='std_trans_rover', reuse=False)\n",
    "# print('wer_correct_before = {:.4f}, wer_correct_after = {:.4f}'.format(wer_correct_before, wer_correct_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = error_type(df_eval_before, std_trans='std_trans_rover')\n",
    "# print('dataset = {:s}, rover_before: count = {:d}, len = {:.1f}, del = {:.2f}%, ins = {:5.2f}%, sub = {:5.2f}%, wer = {:5.2f}%'\\\n",
    "#       .format(dataset, res['CNT'], res['LEN'], res['DEL'], res['INS'], res['SUB'], res['WER']))\n",
    "# res = error_type(df_eval_after, std_trans='std_trans_rover')\n",
    "# print('dataset = {:s}, rover_after : count = {:d}, len = {:.1f}, del = {:.2f}%, ins = {:5.2f}%, sub = {:5.2f}%, wer = {:5.2f}%'\\\n",
    "#       .format(dataset, res['CNT'], res['LEN'], res['DEL'], res['INS'], res['SUB'], res['WER']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset = train-mixed-10h, raw_before   : count = 13815, len = 34.9, del = 1.78%, ins =  0.47%, sub =  3.72%, wer =  5.97%\n",
      "dataset = train-mixed-10h, worst_before  : count = 2763, len = 33.3, del = 6.86%, ins =  1.04%, sub =  7.51%, wer = 15.41%\n",
      "dataset = train-mixed-10h, random_before : count = 2763, len = 34.9, del = 1.68%, ins =  0.48%, sub =  3.75%, wer =  5.91%\n",
      "dataset = train-mixed-10h, longest_before: count = 2763, len = 35.6, del = 0.21%, ins =  1.07%, sub =  3.75%, wer =  5.03%\n",
      "dataset = train-mixed-10h, highest_before: count = 2763, len = 35.2, del = 0.76%, ins =  0.42%, sub =  3.32%, wer =  4.50%\n",
      "dataset = train-mixed-10h, correct_before: count = 2763, len = 35.3, del = 0.31%, ins =  0.30%, sub =  2.42%, wer =  3.04%\n",
      "dataset = train-mixed-10h, best_before   : count = 2763, len = 35.3, del = 0.22%, ins =  0.16%, sub =  1.71%, wer =  2.09%\n",
      "--------------------------------------------------------------------------------------------------------------------------\n",
      "dataset = train-mixed-10h, raw_after    : count = 13803, len = 35.2, del = 0.87%, ins =  0.44%, sub =  3.58%, wer =  4.89%\n",
      "dataset = train-mixed-10h, worst_after   : count = 2762, len = 34.8, del = 2.45%, ins =  0.97%, sub =  7.10%, wer = 10.53%\n",
      "dataset = train-mixed-10h, random_after  : count = 2771, len = 35.1, del = 0.88%, ins =  0.46%, sub =  3.58%, wer =  4.92%\n",
      "dataset = train-mixed-10h, longest_after : count = 2762, len = 35.6, del = 0.21%, ins =  1.01%, sub =  3.91%, wer =  5.12%\n",
      "dataset = train-mixed-10h, highest_after : count = 2762, len = 35.2, del = 0.79%, ins =  0.40%, sub =  3.40%, wer =  4.60%\n",
      "dataset = train-mixed-10h, correct_after : count = 2762, len = 35.3, del = 0.30%, ins =  0.30%, sub =  2.40%, wer =  3.00%\n",
      "dataset = train-mixed-10h, best_after    : count = 2762, len = 35.3, del = 0.23%, ins =  0.16%, sub =  1.67%, wer =  2.05%\n"
     ]
    }
   ],
   "source": [
    "res = error_type(df_before_relabel)\n",
    "print('dataset = {:s}, raw_before   : count = {:d}, len = {:.1f}, del = {:.2f}%, ins = {:5.2f}%, sub = {:5.2f}%, wer = {:5.2f}%'\\\n",
    "      .format(dataset, res['CNT'], res['LEN'], res['DEL'], res['INS'], res['SUB'], res['WER']))\n",
    "res = error_type(df_worst_before)\n",
    "print('dataset = {:s}, worst_before  : count = {:d}, len = {:.1f}, del = {:.2f}%, ins = {:5.2f}%, sub = {:5.2f}%, wer = {:5.2f}%'\\\n",
    "      .format(dataset, res['CNT'], res['LEN'], res['DEL'], res['INS'], res['SUB'], res['WER']))\n",
    "res = error_type(df_before_random_1)\n",
    "print('dataset = {:s}, random_before : count = {:d}, len = {:.1f}, del = {:.2f}%, ins = {:5.2f}%, sub = {:5.2f}%, wer = {:5.2f}%'\\\n",
    "      .format(dataset, res['CNT'], res['LEN'], res['DEL'], res['INS'], res['SUB'], res['WER']))\n",
    "res = error_type(df_longest_before)\n",
    "print('dataset = {:s}, longest_before: count = {:d}, len = {:.1f}, del = {:.2f}%, ins = {:5.2f}%, sub = {:5.2f}%, wer = {:5.2f}%'\\\n",
    "      .format(dataset, res['CNT'], res['LEN'], res['DEL'], res['INS'], res['SUB'], res['WER']))\n",
    "res = error_type(df_highest_before)\n",
    "print('dataset = {:s}, highest_before: count = {:d}, len = {:.1f}, del = {:.2f}%, ins = {:5.2f}%, sub = {:5.2f}%, wer = {:5.2f}%'\\\n",
    "      .format(dataset, res['CNT'], res['LEN'], res['DEL'], res['INS'], res['SUB'], res['WER']))\n",
    "res = error_type(df_eval_before, std_trans='std_trans_rover')\n",
    "print('dataset = {:s}, correct_before: count = {:d}, len = {:.1f}, del = {:.2f}%, ins = {:5.2f}%, sub = {:5.2f}%, wer = {:5.2f}%'\\\n",
    "      .format(dataset, res['CNT'], res['LEN'], res['DEL'], res['INS'], res['SUB'], res['WER']))\n",
    "res = error_type(df_best_before)\n",
    "print('dataset = {:s}, best_before   : count = {:d}, len = {:.1f}, del = {:.2f}%, ins = {:5.2f}%, sub = {:5.2f}%, wer = {:5.2f}%'\\\n",
    "      .format(dataset, res['CNT'], res['LEN'], res['DEL'], res['INS'], res['SUB'], res['WER']))\n",
    "print('-'*122)\n",
    "res = error_type(df_after_relabel)\n",
    "print('dataset = {:s}, raw_after    : count = {:d}, len = {:.1f}, del = {:.2f}%, ins = {:5.2f}%, sub = {:5.2f}%, wer = {:5.2f}%'\\\n",
    "      .format(dataset, res['CNT'], res['LEN'], res['DEL'], res['INS'], res['SUB'], res['WER']))\n",
    "res = error_type(df_worst_after)\n",
    "print('dataset = {:s}, worst_after   : count = {:d}, len = {:.1f}, del = {:.2f}%, ins = {:5.2f}%, sub = {:5.2f}%, wer = {:5.2f}%'\\\n",
    "      .format(dataset, res['CNT'], res['LEN'], res['DEL'], res['INS'], res['SUB'], res['WER']))\n",
    "res = error_type(df_after_random_1)\n",
    "print('dataset = {:s}, random_after  : count = {:d}, len = {:.1f}, del = {:.2f}%, ins = {:5.2f}%, sub = {:5.2f}%, wer = {:5.2f}%'\\\n",
    "      .format(dataset, res['CNT'], res['LEN'], res['DEL'], res['INS'], res['SUB'], res['WER']))\n",
    "res = error_type(df_longest_after)\n",
    "print('dataset = {:s}, longest_after : count = {:d}, len = {:.1f}, del = {:.2f}%, ins = {:5.2f}%, sub = {:5.2f}%, wer = {:5.2f}%'\\\n",
    "      .format(dataset, res['CNT'], res['LEN'], res['DEL'], res['INS'], res['SUB'], res['WER']))\n",
    "res = error_type(df_highest_after)\n",
    "print('dataset = {:s}, highest_after : count = {:d}, len = {:.1f}, del = {:.2f}%, ins = {:5.2f}%, sub = {:5.2f}%, wer = {:5.2f}%'\\\n",
    "      .format(dataset, res['CNT'], res['LEN'], res['DEL'], res['INS'], res['SUB'], res['WER']))\n",
    "res = error_type(df_eval_after, std_trans='std_trans_rover')\n",
    "print('dataset = {:s}, correct_after : count = {:d}, len = {:.1f}, del = {:.2f}%, ins = {:5.2f}%, sub = {:5.2f}%, wer = {:5.2f}%'\\\n",
    "      .format(dataset, res['CNT'], res['LEN'], res['DEL'], res['INS'], res['SUB'], res['WER']))\n",
    "res = error_type(df_best_after)\n",
    "print('dataset = {:s}, best_after    : count = {:d}, len = {:.1f}, del = {:.2f}%, ins = {:5.2f}%, sub = {:5.2f}%, wer = {:5.2f}%'\\\n",
    "      .format(dataset, res['CNT'], res['LEN'], res['DEL'], res['INS'], res['SUB'], res['WER']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crowd = df_gold.copy()\n",
    "df_crowd['gold_trans'] = df_crowd['gold_trans'].apply(lambda x: normalize_trans(x))\n",
    "df_crowd = df_crowd.rename(columns={'std_trans':'std_trans_synthetic'})\n",
    "# random before\n",
    "df_merge_random_before = df_before_random_1[['utt','std_trans']].drop_duplicates(subset=['utt'])\n",
    "df_crowd = df_crowd.merge(df_merge_random_before, on=['utt'], how='left')\n",
    "df_crowd = df_crowd.rename(columns={'std_trans':'std_trans_random_before'})\n",
    "# random after\n",
    "df_merge_random_after = df_after_random_1[['utt','std_trans']].drop_duplicates(subset=['utt'])\n",
    "df_crowd = df_crowd.merge(df_merge_random_after, on=['utt'], how='left')\n",
    "df_crowd = df_crowd.rename(columns={'std_trans':'std_trans_random_after'})\n",
    "df_crowd['std_trans_random_after'] = df_crowd['std_trans_random_after'].fillna(df_crowd['std_trans_random_before'])\n",
    "# longest before\n",
    "df_merge_longest_before = df_longest_before[['utt','std_trans']].drop_duplicates(subset=['utt'])\n",
    "df_crowd = df_crowd.merge(df_merge_longest_before, on=['utt'], how='left')\n",
    "df_crowd = df_crowd.rename(columns={'std_trans':'std_trans_longest_before'})\n",
    "df_crowd['std_trans_longest_before'] = df_crowd['std_trans_longest_before'].fillna(df_crowd['std_trans_random_before'])\n",
    "# longest after\n",
    "df_merge_longest_after = df_longest_after[['utt','std_trans']].drop_duplicates(subset=['utt'])\n",
    "df_crowd = df_crowd.merge(df_merge_longest_after, on=['utt'], how='left')\n",
    "df_crowd = df_crowd.rename(columns={'std_trans':'std_trans_longest_after'})\n",
    "df_crowd['std_trans_longest_after'] = df_crowd['std_trans_longest_after'].fillna(df_crowd['std_trans_random_after'])\n",
    "# highest before\n",
    "df_merge_highest_before = df_highest_before[['utt','std_trans']].drop_duplicates(subset=['utt'])\n",
    "df_crowd = df_crowd.merge(df_merge_highest_before, on=['utt'], how='left')\n",
    "df_crowd = df_crowd.rename(columns={'std_trans':'std_trans_highest_before'})\n",
    "df_crowd['std_trans_highest_before'] = df_crowd['std_trans_highest_before'].fillna(df_crowd['std_trans_random_before'])\n",
    "# highest after\n",
    "df_merge_highest_after = df_highest_after[['utt','std_trans']].drop_duplicates(subset=['utt'])\n",
    "df_crowd = df_crowd.merge(df_merge_highest_after, on=['utt'], how='left')\n",
    "df_crowd = df_crowd.rename(columns={'std_trans':'std_trans_highest_after'})\n",
    "df_crowd['std_trans_highest_after'] = df_crowd['std_trans_highest_after'].fillna(df_crowd['std_trans_random_after'])\n",
    "# correct before\n",
    "df_merge_correct_before = df_eval_before.reset_index()[['utt','std_trans_rover']].drop_duplicates(subset=['utt','std_trans_rover'])\n",
    "df_crowd = df_crowd.merge(df_merge_correct_before, on=['utt'], how='left')\n",
    "df_crowd['std_trans_rover'] = df_crowd['std_trans_rover'].fillna(df_crowd['std_trans_random_before'])\n",
    "df_crowd = df_crowd.rename(columns={'std_trans_rover':'std_trans_correct_before'})\n",
    "# correct after\n",
    "df_merge_correct_after = df_eval_after.reset_index()[['utt','std_trans_rover']].drop_duplicates(subset=['utt','std_trans_rover'])\n",
    "df_crowd = df_crowd.merge(df_merge_correct_after, on=['utt'], how='left')\n",
    "df_crowd['std_trans_rover'] = df_crowd['std_trans_rover'].fillna(df_crowd['std_trans_random_after'])\n",
    "df_crowd = df_crowd.rename(columns={'std_trans_rover':'std_trans_correct_after'})\n",
    "# best before\n",
    "df_merge_best_before = df_best_before[['utt','std_trans']].drop_duplicates(subset=['utt'])\n",
    "df_crowd = df_crowd.merge(df_merge_best_before, on=['utt'], how='left')\n",
    "df_crowd = df_crowd.rename(columns={'std_trans':'std_trans_best_before'})\n",
    "df_crowd['std_trans_best_before'] = df_crowd['std_trans_best_before'].fillna(df_crowd['std_trans_random_before'])\n",
    "# best after\n",
    "df_merge_best_after = df_best_after[['utt','std_trans']].drop_duplicates(subset=['utt'])\n",
    "df_crowd = df_crowd.merge(df_merge_best_after, on=['utt'], how='left')\n",
    "df_crowd = df_crowd.rename(columns={'std_trans':'std_trans_best_after'})\n",
    "df_crowd['std_trans_best_after'] = df_crowd['std_trans_best_after'].fillna(df_crowd['std_trans_random_after'])\n",
    "# worst before\n",
    "df_merge_worst_before = df_worst_before[['utt','std_trans']].drop_duplicates(subset=['utt'])\n",
    "df_crowd = df_crowd.merge(df_merge_worst_before, on=['utt'], how='left')\n",
    "df_crowd = df_crowd.rename(columns={'std_trans':'std_trans_worst_before'})\n",
    "df_crowd['std_trans_worst_before'] = df_crowd['std_trans_worst_before'].fillna(df_crowd['std_trans_random_before'])\n",
    "# worst after\n",
    "df_merge_worst_after = df_worst_after[['utt','std_trans']].drop_duplicates(subset=['utt'])\n",
    "df_crowd = df_crowd.merge(df_merge_worst_after, on=['utt'], how='left')\n",
    "df_crowd = df_crowd.rename(columns={'std_trans':'std_trans_worst_after'})\n",
    "df_crowd['std_trans_worst_after'] = df_crowd['std_trans_worst_after'].fillna(df_crowd['std_trans_random_after'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2763 entries, 0 to 2762\n",
      "Data columns (total 15 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   utt                       2763 non-null   object\n",
      " 1   gold_trans                2763 non-null   object\n",
      " 2   std_trans_synthetic       2763 non-null   object\n",
      " 3   std_trans_random_before   2763 non-null   object\n",
      " 4   std_trans_random_after    2763 non-null   object\n",
      " 5   std_trans_longest_before  2763 non-null   object\n",
      " 6   std_trans_longest_after   2763 non-null   object\n",
      " 7   std_trans_highest_before  2763 non-null   object\n",
      " 8   std_trans_highest_after   2763 non-null   object\n",
      " 9   std_trans_correct_before  2763 non-null   object\n",
      " 10  std_trans_correct_after   2763 non-null   object\n",
      " 11  std_trans_best_before     2763 non-null   object\n",
      " 12  std_trans_best_after      2763 non-null   object\n",
      " 13  std_trans_worst_before    2763 non-null   object\n",
      " 14  std_trans_worst_after     2763 non-null   object\n",
      "dtypes: object(15)\n",
      "memory usage: 345.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_crowd.info()\n",
    "df_crowd.to_csv(crowdpath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crowd_before = df_before_relabel[['utt','gold_trans','std_trans','LifetimeApprovalRate','taskId']].rename(columns={'std_trans':'std_trans_crowd'})\n",
    "df_crowd_before['relabel'] = 0\n",
    "df_crowd_before['approve_rate'] = df_crowd_before['LifetimeApprovalRate'].apply(lambda x: int(x.split('%')[0])/100)\n",
    "df_crowd_after  = df_after_relabel[['utt','gold_trans','std_trans','LifetimeApprovalRate','taskId']].rename(columns={'std_trans':'std_trans_crowd'})\n",
    "df_crowd_after['relabel'] = 1\n",
    "df_crowd_after['approve_rate'] = df_crowd_before['LifetimeApprovalRate'].apply(lambda x: int(x.split('%')[0])/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crowd_before['len_gold_trans'] = df_crowd_before['gold_trans'].apply(lambda x:len(x.split()))\n",
    "df1 = df_crowd_before.groupby(['utt'], as_index=False).nth(0).sort_values(by='len_gold_trans')\n",
    "df2 = df_crowd_before.groupby(['utt'], as_index=False).nth(1).sort_values(by='len_gold_trans')\n",
    "df3 = df_crowd_before.groupby(['utt'], as_index=False).nth(2).sort_values(by='len_gold_trans')\n",
    "df4 = df_crowd_before.groupby(['utt'], as_index=False).nth(3).sort_values(by='len_gold_trans')\n",
    "df5 = df_crowd_before.groupby(['utt'], as_index=False).nth(4).sort_values(by='len_gold_trans')\n",
    "df_crowd_before = pd.concat([df1,df2,df3,df4,df5]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crowd_after['len_gold_trans'] = df_crowd_after['gold_trans'].apply(lambda x:len(x.split()))\n",
    "df1 = df_crowd_after.groupby(['utt'], as_index=False).nth(0).sort_values(by='len_gold_trans')\n",
    "df2 = df_crowd_after.groupby(['utt'], as_index=False).nth(1).sort_values(by='len_gold_trans')\n",
    "df3 = df_crowd_after.groupby(['utt'], as_index=False).nth(2).sort_values(by='len_gold_trans')\n",
    "df4 = df_crowd_after.groupby(['utt'], as_index=False).nth(3).sort_values(by='len_gold_trans')\n",
    "df5 = df_crowd_after.groupby(['utt'], as_index=False).nth(4).sort_values(by='len_gold_trans')\n",
    "df_crowd_after = pd.concat([df1,df2,df3,df4,df5]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27614 entries, 0 to 27613\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   utt              27614 non-null  object \n",
      " 1   taskId           27614 non-null  object \n",
      " 2   gold_trans       27614 non-null  object \n",
      " 3   std_trans_crowd  27614 non-null  object \n",
      " 4   approve_rate     27614 non-null  float64\n",
      " 5   relabel          27614 non-null  int64  \n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "cols = ['utt','taskId','gold_trans','std_trans_crowd','approve_rate','relabel']\n",
    "df_crowd_5 = pd.concat([df_crowd_before[cols], df_crowd_after[cols]]).reset_index(drop=True)\n",
    "df_crowd_5.info()\n",
    "df_crowd_5.to_csv(crowdpath_5, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2763 entries, 0 to 2762\n",
      "Data columns (total 15 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   utt                       2763 non-null   object\n",
      " 1   gold_trans                2763 non-null   object\n",
      " 2   std_trans_synthetic       2763 non-null   object\n",
      " 3   std_trans_random_before   2762 non-null   object\n",
      " 4   std_trans_random_after    2763 non-null   object\n",
      " 5   std_trans_longest_before  2763 non-null   object\n",
      " 6   std_trans_longest_after   2763 non-null   object\n",
      " 7   std_trans_highest_before  2763 non-null   object\n",
      " 8   std_trans_highest_after   2763 non-null   object\n",
      " 9   std_trans_correct_before  2763 non-null   object\n",
      " 10  std_trans_correct_after   2763 non-null   object\n",
      " 11  std_trans_best_before     2763 non-null   object\n",
      " 12  std_trans_best_after      2763 non-null   object\n",
      " 13  std_trans_worst_before    2755 non-null   object\n",
      " 14  std_trans_worst_after     2763 non-null   object\n",
      "dtypes: object(15)\n",
      "memory usage: 323.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_check = pd.read_csv('./data/LibriSpeechCrowd/librispeech_{:s}_crowd.csv'.format(dataset.replace('-','_')))\n",
    "df_check.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset = train-mixed-10h, col = std_trans_worst_before  : count = 2763, len = 33.3, del = 6.86%, ins =  1.04%, sub =  7.51%, wer = 15.41%\n",
      "dataset = train-mixed-10h, col = std_trans_random_before : count = 2763, len = 34.9, del = 1.68%, ins =  0.48%, sub =  3.75%, wer =  5.91%\n",
      "dataset = train-mixed-10h, col = std_trans_longest_before: count = 2763, len = 35.6, del = 0.21%, ins =  1.07%, sub =  3.75%, wer =  5.03%\n",
      "dataset = train-mixed-10h, col = std_trans_highest_before: count = 2763, len = 35.2, del = 0.76%, ins =  0.42%, sub =  3.32%, wer =  4.50%\n",
      "dataset = train-mixed-10h, col = std_trans_correct_before: count = 2763, len = 35.3, del = 0.31%, ins =  0.30%, sub =  2.42%, wer =  3.04%\n",
      "dataset = train-mixed-10h, col = std_trans_best_before   : count = 2763, len = 35.3, del = 0.22%, ins =  0.16%, sub =  1.71%, wer =  2.09%\n",
      "dataset = train-mixed-10h, col = std_trans_worst_after   : count = 2763, len = 34.8, del = 2.45%, ins =  0.97%, sub =  7.11%, wer = 10.53%\n",
      "dataset = train-mixed-10h, col = std_trans_random_after  : count = 2763, len = 35.2, del = 0.87%, ins =  0.46%, sub =  3.55%, wer =  4.88%\n",
      "dataset = train-mixed-10h, col = std_trans_longest_after : count = 2763, len = 35.6, del = 0.21%, ins =  1.01%, sub =  3.91%, wer =  5.13%\n",
      "dataset = train-mixed-10h, col = std_trans_highest_after : count = 2763, len = 35.2, del = 0.79%, ins =  0.40%, sub =  3.41%, wer =  4.61%\n",
      "dataset = train-mixed-10h, col = std_trans_correct_after : count = 2763, len = 35.3, del = 0.30%, ins =  0.30%, sub =  2.41%, wer =  3.00%\n",
      "dataset = train-mixed-10h, col = std_trans_best_after    : count = 2763, len = 35.3, del = 0.23%, ins =  0.16%, sub =  1.67%, wer =  2.06%\n"
     ]
    }
   ],
   "source": [
    "for col in ['std_trans_worst_before','std_trans_random_before','std_trans_longest_before','std_trans_highest_before','std_trans_correct_before','std_trans_best_before',\n",
    "            'std_trans_worst_after','std_trans_random_after','std_trans_longest_after','std_trans_highest_after','std_trans_correct_after','std_trans_best_after']:\n",
    "    res = error_type(df_check, std_trans=col)\n",
    "    print('dataset = {:s}, col = {:24s}: count = {:d}, len = {:.1f}, del = {:.2f}%, ins = {:5.2f}%, sub = {:5.2f}%, wer = {:5.2f}%'\\\n",
    "          .format(dataset, col, res['CNT'], res['LEN'], res['DEL'], res['INS'], res['SUB'], res['WER']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test-other\n",
    "# Approved: count = 14655, wer_avg = 0.1248, wer_min = 0.0500, wer_max = 0.2323\n",
    "# Rejected: count =  1295, wer_avg = 0.7215, wer_min = 0.6877, wer_max = 0.7559\n",
    "\n",
    "# dataset = test-other, approved: count = 14655, len = 17.6, del = 2.77%, ins = 1.33%, sub = 8.34%, wer = 12.43%\n",
    "# dataset = test-other, rejected: count = 1295, len = 9.3, del = 49.31%, ins = 3.91%, sub = 19.34%, wer = 72.56%\n",
    "\n",
    "# Before Relabeling: wer_avg = 0.1661, wer_min = 0.0532, wer_max = 0.3737\n",
    "# After  Relabeling: wer_avg = 0.1248, wer_min = 0.0500, wer_max = 0.2323\n",
    "# Relabeling percent = 8.84%, WER improve = 413 bps\n",
    "# Number of workers: before = 934, after = 989\n",
    "\n",
    "# wer_random1_before = 0.1650, wer_random1_after = 0.1280\n",
    "# wer_oracle2_before = 0.0919, wer_oracle2_after = 0.0812\n",
    "# wer_oracle3_before = 0.0689, wer_oracle3_after = 0.0651\n",
    "# wer_oracle4_before = 0.0591, wer_oracle4_after = 0.0565\n",
    "# wer_oracle5_before = 0.0532, wer_oracle5_after = 0.0500\n",
    "\n",
    "# dataset = test-other, raw_before   : count = 14695, len = 17.0, del = 6.31%, ins =  1.45%, sub =  8.85%, wer = 16.61%\n",
    "# dataset = test-other, random_before : count = 2939, len = 17.0, del = 5.96%, ins =  1.51%, sub =  9.03%, wer = 16.50%\n",
    "# dataset = test-other, longest_before: count = 2939, len = 18.4, del = 0.53%, ins =  3.69%, sub = 10.16%, wer = 14.38%\n",
    "# dataset = test-other, highest_before: count = 2939, len = 17.6, del = 2.60%, ins =  1.22%, sub =  7.83%, wer = 11.65%\n",
    "# dataset = test-other, correct_before: count = 2939, len = 17.6, del = 2.16%, ins =  0.86%, sub =  5.20%, wer =  8.22%\n",
    "# ---------------------------------------------------------------------------------------------------------------------\n",
    "# dataset = test-other, raw_after    : count = 14655, len = 17.6, del = 2.77%, ins =  1.33%, sub =  8.34%, wer = 12.43%\n",
    "# dataset = test-other, random_after  : count = 2977, len = 17.4, del = 2.92%, ins =  1.33%, sub =  8.76%, wer = 13.01%\n",
    "# dataset = test-other, longest_after : count = 2938, len = 18.3, del = 0.47%, ins =  2.97%, sub =  8.98%, wer = 12.42%\n",
    "# dataset = test-other, highest_after : count = 2938, len = 17.6, del = 2.45%, ins =  1.21%, sub =  7.63%, wer = 11.30%\n",
    "# dataset = test-other, correct_after : count = 2938, len = 17.8, del = 1.38%, ins =  0.97%, sub =  5.16%, wer =  7.51%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### dev-other\n",
    "# Approved: count = 14237, wer_avg = 0.0959, wer_min = 0.0413, wer_max = 0.1769\n",
    "# Rejected: count =   998, wer_avg = 0.7465, wer_min = 0.7177, wer_max = 0.7776\n",
    "\n",
    "# dataset = dev-other, approved: count = 14237, len = 17.7, del = 1.67%, ins = 0.95%, sub = 6.90%, wer = 9.52%\n",
    "# dataset = dev-other, rejected: count = 998, len = 8.9, del = 48.94%, ins = 3.54%, sub = 20.47%, wer = 72.95%\n",
    "\n",
    "# Before Relabeling: wer_avg = 0.1269, wer_min = 0.0429, wer_max = 0.2974\n",
    "# After  Relabeling: wer_avg = 0.0959, wer_min = 0.0413, wer_max = 0.1769\n",
    "# Relabeling percent = 7.01%, WER improve = 310 bps\n",
    "# Number of workers: before = 572, after = 620\n",
    "\n",
    "# wer_random1_before = 0.1220, wer_random1_after = 0.0971\n",
    "# wer_oracle2_before = 0.0700, wer_oracle2_after = 0.0626\n",
    "# wer_oracle3_before = 0.0551, wer_oracle3_after = 0.0522\n",
    "# wer_oracle4_before = 0.0474, wer_oracle4_after = 0.0456\n",
    "# wer_oracle5_before = 0.0429, wer_oracle5_after = 0.0413\n",
    "\n",
    "# dataset = dev-other, raw_before   : count = 14320, len = 17.2, del = 4.30%, ins =  1.05%, sub =  7.34%, wer = 12.69%\n",
    "# dataset = dev-other, random_before : count = 2864, len = 17.3, del = 3.74%, ins =  1.02%, sub =  7.43%, wer = 12.20%\n",
    "# dataset = dev-other, longest_before: count = 2864, len = 18.2, del = 0.32%, ins =  2.60%, sub =  7.97%, wer = 10.90%\n",
    "# dataset = dev-other, highest_before: count = 2864, len = 17.7, del = 1.59%, ins =  0.95%, sub =  6.78%, wer =  9.32%\n",
    "# dataset = dev-other, correct_before: count = 2864, len = 17.8, del = 0.91%, ins =  0.75%, sub =  5.03%, wer =  6.69%\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "# dataset = dev-other, raw_after    : count = 14237, len = 17.7, del = 1.67%, ins =  0.95%, sub =  6.90%, wer =  9.52%\n",
    "# dataset = dev-other, random_after  : count = 2943, len = 17.6, del = 1.71%, ins =  1.06%, sub =  7.43%, wer = 10.20%\n",
    "# dataset = dev-other, longest_after : count = 2862, len = 18.1, del = 0.36%, ins =  2.20%, sub =  7.63%, wer = 10.20%\n",
    "# dataset = dev-other, highest_after : count = 2862, len = 17.7, del = 1.80%, ins =  0.95%, sub =  6.76%, wer =  9.51%\n",
    "# dataset = dev-other, correct_after : count = 2862, len = 17.8, del = 0.71%, ins =  0.76%, sub =  4.98%, wer =  6.45%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test-clean\n",
    "# Approved: count = 13097, wer_avg = 0.0578, wer_min = 0.0188, wer_max = 0.1255\n",
    "# Rejected: count =   490, wer_avg = 0.7550, wer_min = 0.7353, wer_max = 0.7754\n",
    "\n",
    "# dataset = test-clean, approved: count = 13097, len = 20.0, del = 1.17%, ins = 0.48%, sub = 4.12%, wer = 5.78%\n",
    "# dataset = test-clean, rejected: count = 490, len = 9.4, del = 57.22%, ins = 2.43%, sub = 15.12%, wer = 74.77%\n",
    "\n",
    "# Before Relabeling: wer_avg = 0.0823, wer_min = 0.0198, wer_max = 0.2259\n",
    "# After  Relabeling: wer_avg = 0.0578, wer_min = 0.0188, wer_max = 0.1255\n",
    "# Relabeling percent = 3.74%, WER improve = 245 bps\n",
    "# Number of workers: before = 515, after = 527\n",
    "\n",
    "# wer_random1_before = 0.0871, wer_random1_after = 0.0574\n",
    "# wer_oracle2_before = 0.0365, wer_oracle2_after = 0.0318\n",
    "# wer_oracle3_before = 0.0263, wer_oracle3_after = 0.0252\n",
    "# wer_oracle4_before = 0.0217, wer_oracle4_after = 0.0213\n",
    "# wer_oracle5_before = 0.0198, wer_oracle5_after = 0.0188\n",
    "\n",
    "# dataset = test-clean, raw_before   : count = 13100, len = 19.5, del = 3.23%, ins =  0.55%, sub =  4.45%, wer =  8.23%\n",
    "# dataset = test-clean, random_before : count = 2620, len = 19.5, del = 3.47%, ins =  0.65%, sub =  4.60%, wer =  8.71%\n",
    "# dataset = test-clean, longest_before: count = 2620, len = 20.3, del = 0.21%, ins =  1.47%, sub =  4.44%, wer =  6.11%\n",
    "# dataset = test-clean, highest_before: count = 2620, len = 20.0, del = 1.04%, ins =  0.42%, sub =  3.63%, wer =  5.09%\n",
    "# dataset = test-clean, correct_before: count = 2620, len = 20.0, del = 0.55%, ins =  0.25%, sub =  2.48%, wer =  3.27%\n",
    "# ---------------------------------------------------------------------------------------------------------------------\n",
    "# dataset = test-clean, raw_after    : count = 13097, len = 20.0, del = 1.17%, ins =  0.48%, sub =  4.12%, wer =  5.78%\n",
    "# dataset = test-clean, random_after  : count = 2629, len = 19.9, del = 1.19%, ins =  0.45%, sub =  4.14%, wer =  5.77%\n",
    "# dataset = test-clean, longest_after : count = 2620, len = 20.3, del = 0.25%, ins =  1.31%, sub =  4.73%, wer =  6.30%\n",
    "# dataset = test-clean, highest_after : count = 2620, len = 20.0, del = 1.12%, ins =  0.45%, sub =  3.61%, wer =  5.17%\n",
    "# dataset = test-clean, correct_after : count = 2620, len = 20.0, del = 0.45%, ins =  0.26%, sub =  2.34%, wer =  3.05%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approved: count = 13476, wer_avg = 0.0502, wer_min = 0.0169, wer_max = 0.1079\n",
    "# Rejected: count =   518, wer_avg = 0.5365, wer_min = 0.5053, wer_max = 0.5702\n",
    "\n",
    "# dataset = dev-clean, approved: count = 13476, len = 20.1, del = 0.91%, ins = 0.42%, sub = 3.68%, wer = 5.01%\n",
    "# dataset = dev-clean, rejected: count = 518, len = 11.5, del = 33.46%, ins = 2.71%, sub = 17.49%, wer = 53.66%\n",
    "\n",
    "# Before Relabeling: wer_avg = 0.0610, wer_min = 0.0180, wer_max = 0.1509\n",
    "# After  Relabeling: wer_avg = 0.0502, wer_min = 0.0169, wer_max = 0.1079\n",
    "# Relabeling percent = 3.84%, WER improve = 108 bps\n",
    "# Number of workers: before = 498, after = 523\n",
    "\n",
    "# wer_random1_before = 0.0642, wer_random1_after = 0.0489\n",
    "# wer_oracle2_before = 0.0302, wer_oracle2_after = 0.0293\n",
    "# wer_oracle3_before = 0.0235, wer_oracle3_after = 0.0223\n",
    "# wer_oracle4_before = 0.0204, wer_oracle4_after = 0.0192\n",
    "# wer_oracle5_before = 0.0180, wer_oracle5_after = 0.0169\n",
    "\n",
    "# dataset = dev-clean, raw_before   : count = 13515, len = 19.9, del = 1.73%, ins =  0.47%, sub =  3.89%, wer =  6.10%\n",
    "# dataset = dev-clean, random_before : count = 2703, len = 19.8, del = 1.97%, ins =  0.50%, sub =  3.96%, wer =  6.42%\n",
    "# dataset = dev-clean, longest_before: count = 2703, len = 20.3, del = 0.23%, ins =  1.24%, sub =  4.04%, wer =  5.51%\n",
    "# dataset = dev-clean, highest_before: count = 2703, len = 20.0, del = 0.86%, ins =  0.36%, sub =  3.44%, wer =  4.66%\n",
    "# dataset = dev-clean, correct_before: count = 2703, len = 20.1, del = 0.44%, ins =  0.26%, sub =  2.24%, wer =  2.94%\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "# dataset = dev-clean, raw_after    : count = 13476, len = 20.1, del = 0.91%, ins =  0.42%, sub =  3.68%, wer =  5.01%\n",
    "# dataset = dev-clean, random_after  : count = 2715, len = 20.0, del = 0.85%, ins =  0.42%, sub =  3.66%, wer =  4.94%\n",
    "# dataset = dev-clean, longest_after : count = 2697, len = 20.4, del = 0.22%, ins =  1.15%, sub =  4.45%, wer =  5.83%\n",
    "# dataset = dev-clean, highest_after : count = 2697, len = 20.1, del = 0.87%, ins =  0.35%, sub =  3.49%, wer =  4.72%\n",
    "# dataset = dev-clean, correct_after : count = 2697, len = 20.1, del = 0.35%, ins =  0.24%, sub =  2.18%, wer =  2.76%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train-mixed-10h\n",
    "# Approved: count = 13803, wer_avg = 0.0489, wer_min = 0.0205, wer_max = 0.1053\n",
    "# Rejected: count =   428, wer_avg = 0.6368, wer_min = 0.6088, wer_max = 0.6676\n",
    "\n",
    "# dataset = train-mixed-10h, approved: count = 13803, len = 35.2, del = 0.87%, ins = 0.44%, sub = 3.58%, wer = 4.89%\n",
    "# dataset = train-mixed-10h, rejected: count = 428, len = 17.1, del = 44.72%, ins = 1.74%, sub = 15.40%, wer = 61.85%\n",
    "\n",
    "# Before Relabeling: wer_avg = 0.0597, wer_min = 0.0209, wer_max = 0.1541\n",
    "# After  Relabeling: wer_avg = 0.0489, wer_min = 0.0205, wer_max = 0.1053\n",
    "# Relabeling percent = 3.10%, WER improve = 108 bps\n",
    "# Number of workers: before = 581, after = 616\n",
    "\n",
    "# wer_random1_before = 0.0576, wer_random1_after = 0.0495\n",
    "# wer_oracle2_before = 0.0301, wer_oracle2_after = 0.0288\n",
    "# wer_oracle3_before = 0.0249, wer_oracle3_after = 0.0242\n",
    "# wer_oracle4_before = 0.0224, wer_oracle4_after = 0.0222\n",
    "# wer_oracle5_before = 0.0209, wer_oracle5_after = 0.0205\n",
    "\n",
    "# dataset = train-mixed-10h, raw_before   : count = 13815, len = 34.9, del = 1.78%, ins =  0.47%, sub =  3.72%, wer =  5.97%\n",
    "# dataset = train-mixed-10h, worst_before  : count = 2763, len = 33.3, del = 6.86%, ins =  1.04%, sub =  7.51%, wer = 15.41%\n",
    "# dataset = train-mixed-10h, random_before : count = 2763, len = 34.9, del = 1.68%, ins =  0.48%, sub =  3.75%, wer =  5.91%\n",
    "# dataset = train-mixed-10h, longest_before: count = 2763, len = 35.6, del = 0.21%, ins =  1.07%, sub =  3.75%, wer =  5.03%\n",
    "# dataset = train-mixed-10h, highest_before: count = 2763, len = 35.2, del = 0.76%, ins =  0.42%, sub =  3.32%, wer =  4.50%\n",
    "# dataset = train-mixed-10h, correct_before: count = 2763, len = 35.3, del = 0.31%, ins =  0.30%, sub =  2.42%, wer =  3.04%\n",
    "# dataset = train-mixed-10h, best_before   : count = 2763, len = 35.3, del = 0.22%, ins =  0.16%, sub =  1.71%, wer =  2.09%\n",
    "# --------------------------------------------------------------------------------------------------------------------------\n",
    "# dataset = train-mixed-10h, raw_after    : count = 13803, len = 35.2, del = 0.87%, ins =  0.44%, sub =  3.58%, wer =  4.89%\n",
    "# dataset = train-mixed-10h, worst_after   : count = 2762, len = 34.8, del = 2.45%, ins =  0.97%, sub =  7.10%, wer = 10.53%\n",
    "# dataset = train-mixed-10h, random_after  : count = 2771, len = 35.1, del = 0.88%, ins =  0.46%, sub =  3.58%, wer =  4.92%\n",
    "# dataset = train-mixed-10h, longest_after : count = 2762, len = 35.6, del = 0.21%, ins =  1.01%, sub =  3.91%, wer =  5.12%\n",
    "# dataset = train-mixed-10h, highest_after : count = 2762, len = 35.2, del = 0.79%, ins =  0.40%, sub =  3.40%, wer =  4.60%\n",
    "# dataset = train-mixed-10h, correct_after : count = 2762, len = 35.3, del = 0.30%, ins =  0.30%, sub =  2.40%, wer =  3.00%\n",
    "# dataset = train-mixed-10h, best_after    : count = 2762, len = 35.3, del = 0.23%, ins =  0.16%, sub =  1.67%, wer =  2.05%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train-other-10h\n",
    "# Approved: count = 15987, wer_avg = 0.0687, wer_min = 0.0285, wer_max = 0.1387\n",
    "# Rejected: count =  2706, wer_avg = 0.8302, wer_min = 0.6832, wer_max = 1.0355\n",
    "\n",
    "# dataset = train-other-10h, approved: count = 15987, len = 31.7, del = 1.53%, ins = 0.54%, sub = 4.76%, wer = 6.83%\n",
    "# dataset = train-other-10h, rejected: count = 2706, len = 25.1, del = 22.59%, ins = 20.71%, sub = 34.89%, wer = 78.19%\n",
    "\n",
    "# Before Relabeling: wer_avg = 0.1571, wer_min = 0.0344, wer_max = 0.4540\n",
    "# After  Relabeling: wer_avg = 0.0687, wer_min = 0.0285, wer_max = 0.1387\n",
    "# Relabeling percent = 16.93%, WER improve = 884 bps\n",
    "# Number of workers: before = 1127, after = 1258\n",
    "\n",
    "# wer_random1_before = 0.1550, wer_random1_after = 0.0695\n",
    "# wer_oracle2_before = 0.0679, wer_oracle2_after = 0.0424\n",
    "# wer_oracle3_before = 0.0514, wer_oracle3_after = 0.0341\n",
    "# wer_oracle4_before = 0.0426, wer_oracle4_after = 0.0312\n",
    "# wer_oracle5_before = 0.0344, wer_oracle5_after = 0.0285\n",
    "\n",
    "# dataset = train-other-10h, raw_before   : count = 21715, len = 31.2, del = 4.86%, ins =  4.39%, sub = 10.02%, wer = 19.26%\n",
    "# dataset = train-other-10h, random_before : count = 3165, len = 31.9, del = 3.60%, ins =  3.42%, sub =  8.49%, wer = 15.50%\n",
    "# dataset = train-other-10h, longest_before: count = 3165, len = 36.4, del = 0.42%, ins = 14.16%, sub = 18.25%, wer = 32.83%\n",
    "# dataset = train-other-10h, highest_before: count = 3165, len = 31.5, del = 1.90%, ins =  0.58%, sub =  5.10%, wer =  7.57%\n",
    "# dataset = train-other-10h, correct_before: count = 3165, len = 31.7, del = 1.43%, ins =  0.45%, sub =  3.69%, wer =  5.56%\n",
    "# --------------------------------------------------------------------------------------------------------------------------\n",
    "# dataset = train-other-10h, raw_after    : count = 15987, len = 31.7, del = 1.53%, ins =  0.54%, sub =  4.76%, wer =  6.83%\n",
    "# dataset = train-other-10h, random_after  : count = 3237, len = 31.2, del = 1.62%, ins =  0.54%, sub =  5.09%, wer =  7.25%\n",
    "# dataset = train-other-10h, longest_after : count = 3165, len = 32.2, del = 0.37%, ins =  1.22%, sub =  5.33%, wer =  6.92%\n",
    "# dataset = train-other-10h, highest_after : count = 3165, len = 31.6, del = 1.79%, ins =  0.54%, sub =  5.02%, wer =  7.35%\n",
    "# dataset = train-other-10h, correct_after : count = 3165, len = 31.9, del = 0.68%, ins =  0.34%, sub =  3.12%, wer =  4.14%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug missing approve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_approved[cols].sort_values(by=['submittime','utt']).reset_index(drop=True)\n",
    "# tmp = df.groupby('utt', as_index=False).size().reset_index(name='counts')\n",
    "# tmp[tmp['counts'] < 5]\n",
    "# df7902 = pd.read_csv('./data/LibriSpeechCrowd/test-other/7902.csv')\n",
    "# df7902['AssignmentStatus'][df7902['Input.audio_url'] == '7902-96594-0015.flac']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr02",
   "language": "python",
   "name": "asr02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
