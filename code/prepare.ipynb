{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crowdsource LibriSpeech Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/Users/gajian/Dropbox/Academia/Database/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Speakers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2484 entries, 14 to 9026\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   SEX      2484 non-null   object \n",
      " 1   SUBSET   2484 non-null   object \n",
      " 2   MINUTES  2484 non-null   float64\n",
      " 3   NAME     2484 non-null   object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 97.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_speaker = pd.read_csv(os.path.join(folder, 'LibriSpeech', 'speaker.csv'))\n",
    "df_speaker.set_index('ID', inplace=True)\n",
    "df_speaker.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exist_speakers = set()\n",
    "for subset in ('train-other-10h','train-mixed-10h','dev-clean','dev-other','test-clean','test-other'):\n",
    "    path = os.path.join(folder, 'LibriSpeech', subset)\n",
    "    for speaker in os.listdir(path):\n",
    "        if not speaker.isnumeric():\n",
    "            continue\n",
    "        exist_speakers.add(int(speaker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers_f = set()\n",
    "speakers_m = set()\n",
    "subset = 'train-other-500'\n",
    "path = os.path.join(folder, 'LibriSpeech', subset)\n",
    "for speaker in os.listdir(path):\n",
    "    if speaker not in exist_speakers and speaker.isnumeric():\n",
    "        if df_speaker.loc[int(speaker),'SEX']=='F':\n",
    "            speakers_f.add(int(speaker))\n",
    "        else:\n",
    "            speakers_m.add(int(speaker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected_speakers_f: 72, selected_speakers_m: 72, hours = 60.00\n"
     ]
    }
   ],
   "source": [
    "selected_speakers_f = sorted(random.sample(list(speakers_f), 72))\n",
    "selected_speakers_m = sorted(random.sample(list(speakers_m), 72))\n",
    "minutes = 0\n",
    "for speaker in selected_speakers_f + selected_speakers_m:\n",
    "    minutes += df_speaker.loc[speaker, 'MINUTES']\n",
    "print('selected_speakers_f: {:d}, selected_speakers_m: {:d}, hours = {:.2f}'.format(len(selected_speakers_f), len(selected_speakers_m), minutes/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for speaker in selected_speakers_f + selected_speakers_m:\n",
    "#     source_dir = '/Users/gajian/Dropbox/Academia/Database/LibriSpeech/train-other-500/{:d}/'.format(speaker)\n",
    "#     target_dir = '/Users/gajian/Dropbox/Academia/Database/LibriSpeech/train-other-60h/{:d}/'.format(speaker)\n",
    "#     !scp -r {source_dir} {target_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Gold Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'train-clean-100' # train-clean-100, train-other-500, train-other-10h\n",
    "librispeech_data = torchaudio.datasets.LIBRISPEECH(folder, url=dataset_name, download=False)\n",
    "data_loader = torch.utils.data.DataLoader(librispeech_data, batch_size=1, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name = train-clean-100, size = 17816\n"
     ]
    }
   ],
   "source": [
    "print('dataset_name = {:s}, size = {:d}'.format(dataset_name, len(data_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gold2std(gold_trans):\n",
    "    lst_gold_trans = gold_trans.split()\n",
    "    lst_std_trans  = []\n",
    "    for word in lst_gold_trans:\n",
    "        # randomly delete 10%\n",
    "        if random.random() > 0.1:\n",
    "            lst_std_trans.append(word)\n",
    "        # randomly insert (repeat) 10%\n",
    "        if random.random() > 0.9:\n",
    "            lst_std_trans.append(word)\n",
    "    return ' '.join(lst_std_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'they were were talking confidentially but when came down down they ceased'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold2std('they were talking confidentially together but when i came down they ceased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length = 60.00 hours, #utterance = 17816\n"
     ]
    }
   ],
   "source": [
    "n = len(data_loader)\n",
    "lst_trans = []\n",
    "total_length = 0\n",
    "i = 0\n",
    "for batch in data_loader:\n",
    "    waveform = batch[0][0]\n",
    "    sample_rate = batch[1][0]\n",
    "    audio_length = batch[0].size()[2] / sample_rate\n",
    "    total_length += audio_length\n",
    "    gold_trans = batch[2][0]\n",
    "    std_trans  = gold2std(gold_trans)\n",
    "    speaker_id = batch[3][0]\n",
    "    chapter_id = batch[4][0]\n",
    "    utterance_id = batch[5][0] \n",
    "    utt = '{:d}_{:d}_{:d}'.format(speaker_id, chapter_id, utterance_id)\n",
    "    # store result\n",
    "    lst_trans.append([utt, gold_trans, std_trans])\n",
    "    # display progress\n",
    "    if i % 10 == 0:\n",
    "        print('Task ready [{:04d}/{:04d}].'.format(i, n), end = '\\r')\n",
    "    i += 1\n",
    "    \n",
    "print('Total length = {:.2f} hours, #utterance = {:d}'.format(total_length/3600, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17816 entries, 0 to 17815\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   utt         17816 non-null  object\n",
      " 1   gold_trans  17816 non-null  object\n",
      " 2   std_trans   17816 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 417.7+ KB\n"
     ]
    }
   ],
   "source": [
    "col1 = ['utt','gold_trans','std_trans']\n",
    "df_trans = pd.DataFrame(lst_trans, columns=col1)\n",
    "df_trans = df_trans.reset_index(drop=True)\n",
    "path = os.path.join(folder, 'LibriSpeech', 'librispeech_{:s}_trans.csv'.format(dataset_name.replace('-','_')))\n",
    "df_trans.to_csv(path, index=False)\n",
    "df_trans.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare MTurk Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(folder, 'LibriSpeech', 'train-clean-100')\n",
    "lst_data_dir = sorted(os.listdir(data_dir))\n",
    "dfs = []\n",
    "\n",
    "for speaker in lst_data_dir:\n",
    "    if not speaker.isnumeric():\n",
    "        continue\n",
    "    chapters = os.listdir(os.path.join(data_dir, speaker))\n",
    "    lst_audio_files = []\n",
    "    for chapter in chapters:\n",
    "        if not chapter.isnumeric():\n",
    "            continue\n",
    "        audio_files = os.listdir(os.path.join(data_dir, speaker, chapter))\n",
    "        lst_audio_files += audio_files\n",
    "    df = pd.DataFrame(data={'audio_url': [os.path.join(x.split('-')[0], x.split('-')[1], x) for x in lst_audio_files if '.txt' not in x]})\n",
    "    dfs.append(df)\n",
    "#         print('speaker = {:s}, num_audio_files = {:03d}'.format(speaker, len(df)))\n",
    "\n",
    "for i in range(12):\n",
    "    out_path = os.path.join(data_dir, 'input_{:02d}.csv'.format(i+1))\n",
    "    df_all = pd.concat(dfs[i*12:i*12+12])\n",
    "    df_all.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare MTurk CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def df2bundle(df, r=2):\n",
    "#     d = {}\n",
    "#     for i in range(r):\n",
    "#         d['audio_url_{:d}'.format(i+1)] = []\n",
    "#     lst_audio_url = sorted(df['audio_url'])\n",
    "#     l = len(lst_audio_url)\n",
    "#     lst_audio_url += ['']*(l-l%5)\n",
    "#     for i in range(l//r+1):\n",
    "#         for j in range(r):\n",
    "#             d['audio_url_{:d}'.format(j+1)].append(lst_audio_url[i*r+j])\n",
    "#     return pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_dir = /Users/gajian/Dropbox/Academia/Database/LibriSpeech/train-clean-100\n"
     ]
    }
   ],
   "source": [
    "# data_dir = os.path.join(folder, 'LibriSpeech', 'train-clean-100')\n",
    "# print('data_dir = {:s}'.format(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_audio_files = 083, out_path = /Users/gajian/Dropbox/Academia/Database/LibriSpeech/train-clean-100/1780/input.csv\n",
      "num_audio_files = 110, out_path = /Users/gajian/Dropbox/Academia/Database/LibriSpeech/train-clean-100/1968/input.csv\n",
      "num_audio_files = 149, out_path = /Users/gajian/Dropbox/Academia/Database/LibriSpeech/train-clean-100/252/input.csv\n",
      "num_audio_files = 124, out_path = /Users/gajian/Dropbox/Academia/Database/LibriSpeech/train-clean-100/2522/input.csv\n",
      "num_audio_files = 170, out_path = /Users/gajian/Dropbox/Academia/Database/LibriSpeech/train-clean-100/2544/input.csv\n",
      "num_audio_files = 116, out_path = /Users/gajian/Dropbox/Academia/Database/LibriSpeech/train-clean-100/2925/input.csv\n",
      "num_audio_files = 080, out_path = /Users/gajian/Dropbox/Academia/Database/LibriSpeech/train-clean-100/3261/input.csv\n",
      "num_audio_files = 150, out_path = /Users/gajian/Dropbox/Academia/Database/LibriSpeech/train-clean-100/3541/input.csv\n",
      "num_audio_files = 133, out_path = /Users/gajian/Dropbox/Academia/Database/LibriSpeech/train-clean-100/3618/input.csv\n",
      "num_audio_files = 189, out_path = /Users/gajian/Dropbox/Academia/Database/LibriSpeech/train-clean-100/4263/input.csv\n",
      "num_audio_files = 121, out_path = /Users/gajian/Dropbox/Academia/Database/LibriSpeech/train-clean-100/4407/input.csv\n",
      "num_audio_files = 122, out_path = /Users/gajian/Dropbox/Academia/Database/LibriSpeech/train-clean-100/4964/input.csv\n",
      "num_audio_files = 108, out_path = /Users/gajian/Dropbox/Academia/Database/LibriSpeech/train-clean-100/5296/input.csv\n",
      "num_audio_files = 138, out_path = /Users/gajian/Dropbox/Academia/Database/LibriSpeech/train-clean-100/5781/input.csv\n",
      "num_audio_files = 100, out_path = /Users/gajian/Dropbox/Academia/Database/LibriSpeech/train-clean-100/6178/input.csv\n",
      "num_audio_files = 134, out_path = /Users/gajian/Dropbox/Academia/Database/LibriSpeech/train-clean-100/6512/input.csv\n",
      "num_audio_files = 135, out_path = /Users/gajian/Dropbox/Academia/Database/LibriSpeech/train-clean-100/6652/input.csv\n",
      "num_audio_files = 057, out_path = /Users/gajian/Dropbox/Academia/Database/LibriSpeech/train-clean-100/6743/input.csv\n",
      "num_audio_files = 131, out_path = /Users/gajian/Dropbox/Academia/Database/LibriSpeech/train-clean-100/7826/input.csv\n",
      "num_audio_files = 185, out_path = /Users/gajian/Dropbox/Academia/Database/LibriSpeech/train-clean-100/7871/input.csv\n",
      "num_audio_files = 170, out_path = /Users/gajian/Dropbox/Academia/Database/LibriSpeech/train-clean-100/8156/input.csv\n",
      "num_audio_files = 179, out_path = /Users/gajian/Dropbox/Academia/Database/LibriSpeech/train-clean-100/844/input.csv\n",
      "num_audio_files = 129, out_path = /Users/gajian/Dropbox/Academia/Database/LibriSpeech/train-clean-100/8799/input.csv\n",
      "num_audio_files = 152, out_path = /Users/gajian/Dropbox/Academia/Database/LibriSpeech/train-clean-100/915/input.csv\n"
     ]
    }
   ],
   "source": [
    "# lst_data_dir = sorted(os.listdir(data_dir))\n",
    "# for speaker in lst_data_dir:\n",
    "#     if not speaker.isnumeric():\n",
    "#         continue\n",
    "#     out_path = os.path.join(data_dir, speaker, 'input.csv')\n",
    "#     chapters = os.listdir(os.path.join(data_dir, speaker))\n",
    "#     lst_audio_files = []\n",
    "#     for chapter in chapters:\n",
    "#         if not chapter.isnumeric():\n",
    "#             continue\n",
    "#         audio_files = os.listdir(os.path.join(data_dir, speaker, chapter))\n",
    "#         lst_audio_files += audio_files\n",
    "#     df = pd.DataFrame(data={'audio_url': [x for x in lst_audio_files if '.txt' not in x]})\n",
    "#     df.to_csv(out_path, index=False)\n",
    "#     print('num_audio_files = {:03d}, out_path = {:s}'.format(len(df), out_path))\n",
    "#     # use bundle\n",
    "#     df2 = df2bundle(df, r=2)\n",
    "#     df5 = df2bundle(df, r=5)\n",
    "#     out_path_2 = os.path.join(data_dir, speaker, 'input2.csv')\n",
    "#     out_path_5 = os.path.join(data_dir, speaker, 'input5.csv')\n",
    "#     df2.to_csv(out_path_2, index=False)\n",
    "#     df5.to_csv(out_path_5, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr02",
   "language": "python",
   "name": "asr02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
